{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-25T08:10:02.966381Z",
     "start_time": "2025-03-25T08:10:00.513068Z"
    }
   },
   "source": [
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import traceback\n",
    "import typing as ty\n",
    "from TALENT.model.models.mlp import MLP\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List\n",
    "from ucimlrepo import fetch_ucirepo"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T08:10:02.978962Z",
     "start_time": "2025-03-25T08:10:02.970548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Бибилотека изначально не поддерживает residual-off режим, также как и отутствие нормализации. Исправим это парой строчек!\n",
    "def reglu(x):\n",
    "    a, b = x.chunk(2, dim=-1)\n",
    "    return a * F.relu(b)\n",
    "\n",
    "\n",
    "def geglu(x):\n",
    "    a, b = x.chunk(2, dim=-1)\n",
    "    return a * F.gelu(b)\n",
    "\n",
    "\n",
    "def get_nonglu_activation_fn(name):\n",
    "    return (\n",
    "        F.relu\n",
    "        if name == 'reglu'\n",
    "        else F.gelu\n",
    "        if name == 'geglu'\n",
    "        else get_activation_fn(name)\n",
    "    )\n",
    "\n",
    "\n",
    "def get_activation_fn(name):\n",
    "    return (\n",
    "        reglu\n",
    "        if name == 'reglu'\n",
    "        else geglu\n",
    "        if name == 'geglu'\n",
    "        else torch.sigmoid\n",
    "        if name == 'sigmoid'\n",
    "        else getattr(F, name)\n",
    "    )\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            *,\n",
    "            d_in: int,\n",
    "            d: int,\n",
    "            d_hidden_factor: float,\n",
    "            n_layers: int,\n",
    "            activation: str,\n",
    "            normalization: ty.Optional[str],\n",
    "            hidden_dropout: float,\n",
    "            residual_dropout: float,\n",
    "            d_out: int,\n",
    "            use_residual: bool = True,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        def make_normalization():\n",
    "            norm_dict = {\n",
    "                'batchnorm': nn.BatchNorm1d,\n",
    "                'layernorm': nn.LayerNorm\n",
    "            }\n",
    "            # Опция отсутствия нормализации\n",
    "            if normalization is None or normalization.lower() == 'none':\n",
    "                return None\n",
    "            return norm_dict[normalization.lower()](d)\n",
    "\n",
    "        self.use_residual = use_residual\n",
    "        self.main_activation = get_activation_fn(activation)\n",
    "        self.last_activation = get_nonglu_activation_fn(activation)\n",
    "        self.residual_dropout = residual_dropout\n",
    "        self.hidden_dropout = hidden_dropout\n",
    "\n",
    "        d_hidden = int(d * d_hidden_factor)\n",
    "\n",
    "        self.first_layer = nn.Linear(d_in, d)\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        for _ in range(n_layers):\n",
    "            layer = nn.ModuleDict({\n",
    "                'linear0': nn.Linear(\n",
    "                    d, d_hidden * (2 if activation.endswith('glu') else 1)\n",
    "                ),\n",
    "                'linear1': nn.Linear(d_hidden, d),\n",
    "            })\n",
    "            norm = make_normalization()\n",
    "            if norm:\n",
    "                layer['norm'] = norm\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        self.last_normalization = make_normalization()\n",
    "        self.head = nn.Linear(d, d_out)\n",
    "\n",
    "    def forward(self, x: Tensor, x_cat: Tensor = None) -> Tensor:\n",
    "        x = self.first_layer(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            z = x\n",
    "            if 'norm' in layer:\n",
    "                z = layer['norm'](z)\n",
    "            z = layer['linear0'](z)\n",
    "            z = self.main_activation(z)\n",
    "            if self.hidden_dropout:\n",
    "                z = F.dropout(z, self.hidden_dropout, self.training)\n",
    "            z = layer['linear1'](z)\n",
    "            if self.residual_dropout:\n",
    "                z = F.dropout(z, self.residual_dropout, self.training)\n",
    "            # Вкл/Выкл residual\n",
    "            x = x + z if self.use_residual else z\n",
    "\n",
    "        if self.last_normalization:\n",
    "            x = self.last_normalization(x)\n",
    "        x = self.last_activation(x)\n",
    "        x = self.head(x)\n",
    "        x = x.squeeze(-1)\n",
    "        return x\n"
   ],
   "id": "e968c66f90c53cd0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T08:10:03.372015Z",
     "start_time": "2025-03-25T08:10:03.111941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "id": "e4c2fd9d580138b4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T08:10:03.429666Z",
     "start_time": "2025-03-25T08:10:03.394213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_phishing():\n",
    "    heart_disease = fetch_ucirepo(id=327)\n",
    "\n",
    "    X = heart_disease.data.features\n",
    "    y = np.array(heart_disease.data.targets.values.ravel(), dtype=np.str_)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def load_tuandromb():\n",
    "    data = pd.read_csv(\"data/TUANDROMD.csv\")\n",
    "    data = data[~data[\"Label\"].isna()]\n",
    "\n",
    "    X = data.drop(columns=[\"Label\"])\n",
    "    y = data[\"Label\"]\n",
    "    return X, y"
   ],
   "id": "87545a71aabde344",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T08:10:03.461579Z",
     "start_time": "2025-03-25T08:10:03.456646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Функция инстанциации модели (4 варианта). Некоторые параметры не будут менятся ввиду ограниченности ресурсов\n",
    "def select_model(model_type: str, d_in, d_out, params) -> nn.Module:\n",
    "    if model_type == \"mlp\":\n",
    "        return MLP(\n",
    "            d_in=d_in,\n",
    "            d_out=d_out,\n",
    "            d_layers=[64, 64],\n",
    "            dropout=params.get(\"dropout\")\n",
    "        )\n",
    "\n",
    "    elif model_type == \"mlp_norm\":\n",
    "        return ResNet(\n",
    "            d_in=d_in,\n",
    "            d=params.get(\"d\", 256),\n",
    "            d_hidden_factor=1.0,\n",
    "            n_layers=3,\n",
    "            activation=params.get(\"activation\"),\n",
    "            normalization=params.get(\"normalization\"),\n",
    "            hidden_dropout=0.15,\n",
    "            residual_dropout=0.15,\n",
    "            use_residual=False,\n",
    "            d_out=d_out\n",
    "        )\n",
    "\n",
    "    elif model_type == \"mlp_residual\":\n",
    "        return ResNet(\n",
    "            d_in=d_in,\n",
    "            d=params.get(\"d\", 256),\n",
    "            d_hidden_factor=1.0,\n",
    "            n_layers=3,\n",
    "            activation=params.get(\"activation\"),\n",
    "            normalization='none',\n",
    "            hidden_dropout=0.15,\n",
    "            residual_dropout=params.get(\"residual_dropout\"),\n",
    "            use_residual=True,\n",
    "            d_out=d_out\n",
    "        )\n",
    "\n",
    "    elif model_type == \"resnet\":\n",
    "        return ResNet(\n",
    "            d_in=d_in,\n",
    "            d=params.get(\"d\", 256),\n",
    "            d_hidden_factor=1.0,\n",
    "            n_layers=3,\n",
    "            activation=params.get(\"activation\"),\n",
    "            normalization=params.get(\"normalization\"),\n",
    "            hidden_dropout=0.15,\n",
    "            residual_dropout=params.get(\"residual_dropout\"),\n",
    "            use_residual=True,\n",
    "            d_out=d_out\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Unknown model_type: {model_type}. Choose from ['mlp', 'mlp_norm', 'mlp_residual', 'resnet'].\")\n"
   ],
   "id": "9ca5bba640bb683",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T08:10:03.510989Z",
     "start_time": "2025-03-25T08:10:03.507468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Словарь для Grid search, параметры зависят от выбранной модели\n",
    "param_grids: Dict[str, Dict[str, List]] = {\n",
    "    \"mlp\": {\n",
    "        \"dropout\": [0.01, 0.1, 0.2],\n",
    "    },\n",
    "    \"mlp_norm\": {\n",
    "        \"dropout\": [0.01, 0.1, 0.2],\n",
    "        \"activation\": [\"relu\", \"gelu\", \"sigmoid\"],\n",
    "        \"normalization\": [\"batchnorm\", \"layernorm\"],\n",
    "    },\n",
    "    \"mlp_residual\": {\n",
    "        \"dropout\": [0.01, 0.1, 0.2],\n",
    "        \"activation\": [\"relu\", \"gelu\", \"sigmoid\"],\n",
    "        \"residual_dropout\": [0.01, 0.1, 0.2],\n",
    "    },\n",
    "    \"resnet\": {\n",
    "        \"dropout\": [0.01, 0.1, 0.2],\n",
    "        \"activation\": [\"relu\", \"gelu\", \"sigmoid\"],\n",
    "        \"normalization\": [\"batchnorm\", \"layernorm\"],\n",
    "        \"residual_dropout\": [0.01, 0.1, 0.2],\n",
    "    }\n",
    "}\n"
   ],
   "id": "73927e849dbaae34",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T08:10:03.566084Z",
     "start_time": "2025-03-25T08:10:03.557612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_param_combinations(param_grid: Dict[str, List]) -> List[Dict]:\n",
    "    keys = param_grid.keys()\n",
    "    values = param_grid.values()\n",
    "    return [dict(zip(keys, combo)) for combo in product(*values)]\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=10, lr=1e-3):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    sample_x, _ = next(iter(train_loader))\n",
    "    sample_out = model(sample_x.to(device), x_cat=None)\n",
    "    d_out = sample_out.shape[1] if len(sample_out.shape) > 1 else 1\n",
    "\n",
    "    is_binary = d_out == 1\n",
    "    criterion = torch.nn.BCEWithLogitsLoss() if is_binary else torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb, x_cat=None)\n",
    "            loss = criterion(preds, yb.float() if is_binary else yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device)\n",
    "            preds = model(xb, x_cat=None)\n",
    "            if is_binary:\n",
    "                preds = (torch.sigmoid(preds) > 0.5).int()\n",
    "            else:\n",
    "                preds = torch.argmax(preds, dim=1)\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(yb)\n",
    "\n",
    "    y_pred = torch.cat(all_preds).numpy()\n",
    "    y_true = torch.cat(all_labels).numpy()\n",
    "    return balanced_accuracy_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "def grid_search_models(X, y, param_grids, d_in, d_out, select_model_fn, epochs=5, batch_size=32):\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.long if d_out > 1 else torch.float32)\n",
    "\n",
    "    # Грузим данные\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=batch_size)\n",
    "\n",
    "    best_overall = {\n",
    "        \"model\": None,\n",
    "        \"model_type\": None,\n",
    "        \"params\": None,\n",
    "        \"score\": -1\n",
    "    }\n",
    "\n",
    "    best_per_model = {\n",
    "        model_type: {\"score\": -1, \"params\": None}\n",
    "        for model_type in param_grids\n",
    "    }\n",
    "\n",
    "    total_combinations = sum(len(get_param_combinations(param_grids[k])) for k in param_grids)\n",
    "    pbar = tqdm(total=total_combinations, desc=\"Searching models\")\n",
    "\n",
    "    # Наш лютый цикл для перебора\n",
    "    for model_type, grid in param_grids.items():\n",
    "        for param_set in get_param_combinations(grid):\n",
    "            try:\n",
    "                model = select_model_fn(model_type, d_in=d_in, d_out=d_out, params=param_set)\n",
    "                score = train_model(model, train_loader, val_loader, epochs=epochs)\n",
    "\n",
    "                if score > best_per_model[model_type][\"score\"]:\n",
    "                    best_per_model[model_type][\"score\"] = score\n",
    "                    best_per_model[model_type][\"params\"] = param_set\n",
    "\n",
    "                if score > best_overall[\"score\"]:\n",
    "                    best_overall.update({\n",
    "                        \"model\": model,\n",
    "                        \"model_type\": model_type,\n",
    "                        \"params\": param_set,\n",
    "                        \"score\": score\n",
    "                    })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[{model_type}] Failed with params: {param_set}\")\n",
    "                traceback.print_exc()\n",
    "            finally:\n",
    "                pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "    return {\n",
    "        \"best_model\": best_overall[\"model\"],\n",
    "        \"best_model_type\": best_overall[\"model_type\"],\n",
    "        \"best_params\": best_overall[\"params\"],\n",
    "        \"best_score\": best_overall[\"score\"],\n",
    "        \"best_per_model\": best_per_model\n",
    "    }\n"
   ],
   "id": "2f7417d219ac872b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T08:10:03.620969Z",
     "start_time": "2025-03-25T08:10:03.617377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_data(X, y):\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "    results = grid_search_models(\n",
    "        X=X,\n",
    "        y=y,\n",
    "        param_grids=param_grids,\n",
    "        d_in=X.shape[1],\n",
    "        d_out=len(le.classes_),\n",
    "        select_model_fn=select_model,\n",
    "        epochs=10,\n",
    "        batch_size=64,\n",
    "    )\n",
    "\n",
    "    print(\"Best overall model:\", results[\"best_model_type\"])\n",
    "    print(\"Best score:\", results[\"best_score\"])\n",
    "    print(\"Best params:\", results[\"best_params\"])\n",
    "\n",
    "    for model_type, info in results[\"best_per_model\"].items():\n",
    "        print(f\"\\n[{model_type}] best score = {info['score']:.4f}\")\n",
    "        print(\"params:\", info[\"params\"])"
   ],
   "id": "34a4c5c4cba6d9dc",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T08:10:26.034198Z",
     "start_time": "2025-03-25T08:10:03.667497Z"
    }
   },
   "cell_type": "code",
   "source": "process_data(*load_breast_cancer(return_X_y=True))",
   "id": "8e9eb029b9af002e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching models: 100%|██████████| 102/102 [00:22<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best overall model: mlp\n",
      "Best score: 0.9883720930232558\n",
      "Best params: {'dropout': 0.01}\n",
      "\n",
      "[mlp] best score = 0.9884\n",
      "params: {'dropout': 0.01}\n",
      "\n",
      "[mlp_norm] best score = 0.9884\n",
      "params: {'dropout': 0.2, 'activation': 'sigmoid', 'normalization': 'layernorm'}\n",
      "\n",
      "[mlp_residual] best score = 0.9884\n",
      "params: {'dropout': 0.01, 'activation': 'sigmoid', 'residual_dropout': 0.1}\n",
      "\n",
      "[resnet] best score = 0.9884\n",
      "params: {'dropout': 0.01, 'activation': 'sigmoid', 'normalization': 'layernorm', 'residual_dropout': 0.1}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T08:16:38.914851Z",
     "start_time": "2025-03-25T08:10:26.048111Z"
    }
   },
   "cell_type": "code",
   "source": "process_data(*load_phishing())",
   "id": "17825fc07b0e36aa",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching models: 100%|██████████| 102/102 [06:09<00:00,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best overall model: resnet\n",
      "Best score: 0.9658320692126889\n",
      "Best params: {'dropout': 0.1, 'activation': 'relu', 'normalization': 'batchnorm', 'residual_dropout': 0.1}\n",
      "\n",
      "[mlp] best score = 0.9546\n",
      "params: {'dropout': 0.01}\n",
      "\n",
      "[mlp_norm] best score = 0.9600\n",
      "params: {'dropout': 0.01, 'activation': 'relu', 'normalization': 'layernorm'}\n",
      "\n",
      "[mlp_residual] best score = 0.9642\n",
      "params: {'dropout': 0.1, 'activation': 'relu', 'residual_dropout': 0.1}\n",
      "\n",
      "[resnet] best score = 0.9658\n",
      "params: {'dropout': 0.1, 'activation': 'relu', 'normalization': 'batchnorm', 'residual_dropout': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T08:22:45.653923Z",
     "start_time": "2025-03-25T08:16:38.974216Z"
    }
   },
   "cell_type": "code",
   "source": "process_data(*load_phishing())\n",
   "id": "bb3ed89c25c4afc9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching models: 100%|██████████| 102/102 [06:03<00:00,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best overall model: mlp_residual\n",
      "Best score: 0.965333644501492\n",
      "Best params: {'dropout': 0.1, 'activation': 'relu', 'residual_dropout': 0.2}\n",
      "\n",
      "[mlp] best score = 0.9528\n",
      "params: {'dropout': 0.01}\n",
      "\n",
      "[mlp_norm] best score = 0.9606\n",
      "params: {'dropout': 0.1, 'activation': 'gelu', 'normalization': 'layernorm'}\n",
      "\n",
      "[mlp_residual] best score = 0.9653\n",
      "params: {'dropout': 0.1, 'activation': 'relu', 'residual_dropout': 0.2}\n",
      "\n",
      "[resnet] best score = 0.9647\n",
      "params: {'dropout': 0.2, 'activation': 'relu', 'normalization': 'layernorm', 'residual_dropout': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Видим, что ResNet почти везде выигрывает, обходя на несколько процетов несколько навороченные версии. Тем не менее, наблюдаем, что параметры сильно зависят от данных, где-то может произойти overfitting, поэтому выскорий dropout помогает сохранить генерализующие свойства, где-то, наоборот, он наименее существенный и GridSearch минимизирует регуляризацию.\n",
    "\n",
    "Забавно, что на третем датасете, mlp_residual выиграл resnet (хоть и на уровне погрешности). Повторюсь, ввиду ограниченности размерности простраства перебора, используемая ResNet не обучалась на векторе аргументов, дающий глоабльный максимум по призводительности. Более того, phishing dataset мог оказаться слишком маленьким, а сложность ResNet и реугляризация слишком существенны, чтобы достигнуть полной сходимости."
   ],
   "id": "87bc2b0af4cc49b8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
