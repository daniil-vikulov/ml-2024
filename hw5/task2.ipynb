{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-24T13:07:44.029300Z",
     "start_time": "2025-03-24T13:07:44.026092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "from TALENT.model.models.tabr import TabR\n",
    "from ucimlrepo import fetch_ucirepo"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T13:07:44.042585Z",
     "start_time": "2025-03-24T13:07:44.039625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device_type)"
   ],
   "id": "c77af4a8cad651e8",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T13:07:44.095080Z",
     "start_time": "2025-03-24T13:07:44.091589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_phishing():\n",
    "    heart_disease = fetch_ucirepo(id=327)\n",
    "\n",
    "    X = heart_disease.data.features\n",
    "    y = np.array(heart_disease.data.targets.values.ravel(), dtype=np.str_)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def load_tuandromb():\n",
    "    data = pd.read_csv(\"data/TUANDROMD.csv\")\n",
    "    data = data[~data[\"Label\"].isna()]\n",
    "\n",
    "    X = data.drop(columns=[\"Label\"])\n",
    "    y = data[\"Label\"]\n",
    "    return X, y"
   ],
   "id": "75558fe28214240e",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T13:07:44.146123Z",
     "start_time": "2025-03-24T13:07:44.135798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TabRWrapper:\n",
    "    def __init__(\n",
    "            self,\n",
    "            X: Tuple[torch.Tensor, Optional[torch.Tensor]],\n",
    "            y: torch.Tensor,\n",
    "            n_classes: int = 2,\n",
    "    ):\n",
    "        # Сохраняем числовые и категориальные признаки, целевые метки и информацию о размере\n",
    "        self.X_num, self.X_cat = X\n",
    "        self.y = y\n",
    "        self.num_features = self.X_num.shape[1]\n",
    "        self.n_cat_features = self.X_cat.shape[1] if self.X_cat is not None else 0\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        # Инициализируем модель\n",
    "        self._init_model()\n",
    "\n",
    "    def _init_model(self):\n",
    "        # Параметры модели TabR (определяют архитектуру encoder'а и predictor'а), вытащены из библиотеки\n",
    "        model_params = {\n",
    "            \"n_num_features\": self.num_features,\n",
    "            \"n_cat_features\": self.n_cat_features,\n",
    "            \"n_classes\": self.n_classes,\n",
    "            \"num_embeddings\": None,\n",
    "            \"d_main\": 265,\n",
    "            \"context_dropout\": 0.3892,\n",
    "            \"d_multiplier\": 2.0,\n",
    "            \"encoder_n_blocks\": 0,\n",
    "            \"predictor_n_blocks\": 1,\n",
    "            \"mixer_normalization\": \"auto\",\n",
    "            \"dropout0\": 0.3885,\n",
    "            \"dropout1\": 0.0,\n",
    "            \"normalization\": \"LayerNorm\",\n",
    "            \"activation\": \"ReLU\",\n",
    "        }\n",
    "\n",
    "        # Инстанциируем модель\n",
    "        self.model = TabR(**model_params).to(device)\n",
    "\n",
    "    def fit(\n",
    "            self,\n",
    "            epochs: int = 10,\n",
    "            batch_size: int = 64,\n",
    "            lr: float = 1e-3,\n",
    "            context_size: int = 5,\n",
    "    ):\n",
    "        # Оптимизатор и функция потерь\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        dataset_size = self.y.size(0)\n",
    "        self.model.train()\n",
    "\n",
    "        # Проходим по эпохам\n",
    "        for _ in tqdm(range(epochs)):\n",
    "            epoch_loss = 0.0\n",
    "            perm = torch.randperm(dataset_size)  # случайный порядок сэмплов для аугментации\n",
    "\n",
    "            # Разделяем на батчи\n",
    "            for i in range(0, dataset_size, batch_size):\n",
    "                idx = perm[i:i + batch_size]\n",
    "\n",
    "                # Загружаем батч входов и меток\n",
    "                x_num_batch = self.X_num[idx].to(device)\n",
    "                x_cat_batch = self.X_cat[idx].to(device) if self.X_cat is not None else None\n",
    "                y_batch = self.y[idx].long().to(device)\n",
    "\n",
    "                # Выбираем случайный контекст (другие точки для сравнения)\n",
    "                candidate_idx = torch.randperm(dataset_size)[:batch_size]\n",
    "                cx_num = self.X_num[candidate_idx].to(device)\n",
    "                cx_cat = self.X_cat[candidate_idx].to(device) if self.X_cat is not None else None\n",
    "                cy = self.y[candidate_idx].to(device)\n",
    "\n",
    "                # Прямой проход через модель\n",
    "                output = self.model(\n",
    "                    x_num=x_num_batch,\n",
    "                    x_cat=x_cat_batch,\n",
    "                    y=y_batch,\n",
    "                    candidate_x_num=cx_num,\n",
    "                    candidate_x_cat=cx_cat,\n",
    "                    candidate_y=cy,\n",
    "                    context_size=context_size,\n",
    "                    is_train=True,\n",
    "                )\n",
    "\n",
    "                # Вычисляем ошибку, обратный проход и шаг оптимизации\n",
    "                loss = criterion(output, y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "    def predict(self, X: Tuple[torch.Tensor, Optional[torch.Tensor]], context_size: int = 5) -> torch.Tensor:\n",
    "        self.model.eval()\n",
    "\n",
    "        x_num, x_cat = X\n",
    "        x_num = x_num.to(device)\n",
    "        x_cat = x_cat.to(device) if x_cat is not None else None\n",
    "\n",
    "        # Контекст - вся обучающая выборка\n",
    "        candidate_x_num = self.X_num.to(device)\n",
    "        candidate_x_cat = self.X_cat.to(device) if self.X_cat is not None else None\n",
    "        candidate_y = self.y.to(device)\n",
    "\n",
    "        # Прямой проход (без градиентов)\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(\n",
    "                x_num=x_num,\n",
    "                x_cat=x_cat,\n",
    "                y=None,\n",
    "                candidate_x_num=candidate_x_num,\n",
    "                candidate_x_cat=candidate_x_cat,\n",
    "                candidate_y=candidate_y,\n",
    "                context_size=context_size,\n",
    "                is_train=False,\n",
    "            )\n",
    "\n",
    "            # Выбираем метку с максимальной вероятностью\n",
    "            return torch.argmax(logits, dim=1)\n",
    "\n",
    "    def compare_neighbor_spaces(self, k: int):\n",
    "        # Стандартизация признаков\n",
    "        scaler = StandardScaler()\n",
    "        X_std = scaler.fit_transform(self.X_num.numpy())\n",
    "\n",
    "        # Применяем encode-ing\n",
    "        with torch.no_grad():\n",
    "            x_tensor = torch.tensor(X_std, dtype=torch.float32).to(device)\n",
    "        z, _ = self.model._encode(x_tensor, None)\n",
    "        Z = z.cpu().detach().numpy()\n",
    "\n",
    "        # Находим ближайших соседей в исходном пространстве (Евклид)\n",
    "        nn_euc_std = NearestNeighbors(n_neighbors=k, metric=\"euclidean\").fit(X_std)\n",
    "\n",
    "        # В скрытом пространстве (Евклид)\n",
    "        nn_euc_latent = NearestNeighbors(n_neighbors=k, metric=\"euclidean\").fit(Z)\n",
    "\n",
    "        _, neighbors_std = nn_euc_std.kneighbors(X_std)\n",
    "        _, neighbors_latent = nn_euc_latent.kneighbors(Z)\n",
    "\n",
    "        # Используем псевдообратную матрицу (может быть вырожденной) для метрики Махаланобиса\n",
    "        VI = np.linalg.pinv(np.cov(X_std.T))\n",
    "        nn_mahal_std = NearestNeighbors(n_neighbors=k, metric=\"mahalanobis\", metric_params={\"VI\": VI}).fit(X_std)\n",
    "        _, neighbors_mahal = nn_mahal_std.kneighbors(X_std)\n",
    "\n",
    "        # Считаем перекрытие соседей\n",
    "        overlaps_euclidean = []\n",
    "        overlaps_mahalanobis = []\n",
    "\n",
    "        for i in range(len(X_std)):\n",
    "            eu = len(set(neighbors_std[i]) & set(neighbors_latent[i]))\n",
    "            ma = len(set(neighbors_mahal[i]) & set(neighbors_latent[i]))\n",
    "            overlaps_euclidean.append(eu)\n",
    "            overlaps_mahalanobis.append(ma)\n",
    "\n",
    "        overlaps_euclidean = np.array(overlaps_euclidean)\n",
    "        overlaps_mahalanobis = np.array(overlaps_mahalanobis)\n",
    "\n",
    "        print(f\"Average Euclidean overlap: {overlaps_euclidean.mean():.2f} / {k}\")\n",
    "        print(f\"Average Mahalanobis overlap: {overlaps_mahalanobis.mean():.2f} / {k}\")\n",
    "\n",
    "        low_overlap_idxs = np.where(overlaps_euclidean <= 1)[0]\n",
    "        print(f\"{len(low_overlap_idxs)} samples have ≤1 Euclidean neighbor in common with encoded space\")\n"
   ],
   "id": "5e4a4ac41243d691",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T13:07:44.199413Z",
     "start_time": "2025-03-24T13:07:44.195797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_method(X, y):\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X=X)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    n_classes = len(label_encoder.classes_)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    model = TabRWrapper((torch.Tensor(X_train), None), torch.Tensor(y_train), n_classes)\n",
    "\n",
    "    model.fit(epochs=100)\n",
    "    pred = model.predict((torch.Tensor(X_test), None))\n",
    "    model.compare_neighbor_spaces(20)\n",
    "\n",
    "    accuracy = balanced_accuracy_score(y_test, pred.cpu())\n",
    "    print(f\"Balanced accuracy: {accuracy}\")"
   ],
   "id": "67c615e819f69a0b",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T13:07:47.724603Z",
     "start_time": "2025-03-24T13:07:44.247700Z"
    }
   },
   "cell_type": "code",
   "source": "apply_method(*load_breast_cancer(return_X_y=True))",
   "id": "ae647b9b4f45280b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 29.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Euclidean overlap: 14.44 / 20\n",
      "Average Mahalanobis overlap: 7.30 / 20\n",
      "0 samples have ≤1 Euclidean neighbor in common with encoded space\n",
      "Balanced accuracy: 0.9448795180722891\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T13:09:37.335926Z",
     "start_time": "2025-03-24T13:07:47.742792Z"
    }
   },
   "cell_type": "code",
   "source": "apply_method(*load_tuandromb())",
   "id": "b171813448273eb3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:29<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Euclidean overlap: 15.73 / 20\n",
      "Average Mahalanobis overlap: 5.53 / 20\n",
      "20 samples have ≤1 Euclidean neighbor in common with encoded space\n",
      "Balanced accuracy: 0.9824932130016876\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T13:10:42.664244Z",
     "start_time": "2025-03-24T13:09:37.421585Z"
    }
   },
   "cell_type": "code",
   "source": "apply_method(*load_phishing())",
   "id": "7fc2cbc319da5127",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:56<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Euclidean overlap: 10.16 / 20\n",
      "Average Mahalanobis overlap: 9.79 / 20\n",
      "12 samples have ≤1 Euclidean neighbor in common with encoded space\n",
      "Balanced accuracy: 0.9614295802043163\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Наша моделька из TabR (вопреки трудостям с установкой либы) показала хорошие результаты на всех трёх датаасетах.\n",
    "\n",
    "В во всех трёх случаях количество пересечений в Евклидовом пространстве больше, чем в пространстве Махаланобисоа\n",
    "\n",
    "В датасетаз 2 и 3 есть сэмплы с низким пересечением, что говорит о наличие выбросов в данных\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "e5cc3a85364d5f9a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
