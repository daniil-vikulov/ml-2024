В первой задаче я использовал ТОЛЬКО модели из des подпакета библиотеки, так как они осуществляют подбор подмножества наиболее компетьтентных классификаторов и ансамблирует их

KNORA-U (K-Nearest Oracles Union)
Выбираем те классификаторы, которые верно классифицируют как минмиум один сэмпл из тестовой выбороки. Далее выбираем
модели с самым больших voting - количество верно угаданых сэпмплов

KNORA-E
В отличие от предыдущего, ищем те, которые классифициует perfectly всех k соседей из теста. Если ни один не справляется perfectly, уменьшает k, убирааем модели с меньшим количество предикта

KNOP (K-Nearest Output Profiles)
Смотрим не на правильность, а на схожесть результата классификатров при классификации тестовой выборки

DESP (Dynamic Ensemble Selection Performance)
Берём на основе вероятности

DESKNN (Dynamic Ensemble Selection KNN)
Похож на KNORA, помимо правильности классификации учитвает вероятность